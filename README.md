# Sistema Agentic AI Multi-Agente para Procesamiento de Documentos

**Universidad Nacional de Colombia - Sede MedellÃ­n**  
**Procesamiento del Lenguaje Natural (PLN)**  
**PrÃ¡ctica 2: Agentic AI con LLMs y LangChain 1.0**

## ğŸ“‹ DescripciÃ³n

Sistema multi-agente basado en LangChain 1.0 que implementa RAG (Retrieval Augmented Generation) para anÃ¡lisis inteligente de documentos. El sistema integra 5 agentes especializados utilizando los LLMs de Groq (familia Llama) de forma diferenciada segÃºn las necesidades de cada componente.

**Dominio de aplicaciÃ³n:** Agricultura - anÃ¡lisis de documentos sobre tÃ©cnicas agrÃ­colas, manejo de cultivos, sostenibilidad, y prÃ¡cticas de producciÃ³n.

## ğŸ—ï¸ Arquitectura del Sistema

### Agentes Implementados

1. **DocumentIndexer (Agente de IndexaciÃ³n)**
   - Carga documentos (PDF/TXT/HTML)
   - Limpieza, chunking y generaciÃ³n de embeddings
   - IndexaciÃ³n en FAISS

2. **QueryClassifier (Agente Clasificador)**
   - **LLM:** Groq (Llama 3.3 70B Versatile)
   - **JustificaciÃ³n:** Llama 3.3 70B ofrece excelente capacidad de interpretaciÃ³n del lenguaje natural y comprensiÃ³n contextual profunda con velocidad superior, esencial para clasificar intenciones con precisiÃ³n
   - Clasifica consultas en 4 categorÃ­as: bÃºsqueda, resumen, comparaciÃ³n, general

3. **SemanticRetriever (Agente Recuperador)**
   - **LLM:** Groq (Llama 3.1 8B Instant)
   - **JustificaciÃ³n:** Llama 3.1 8B Instant proporciona velocidad de inferencia excepcional, crÃ­tica para recuperaciÃ³n ultrarrÃ¡pida de documentos
   - BÃºsqueda semÃ¡ntica en FAISS

4. **RAGResponseGenerator (Agente Generador)**
   - **LLM:** Groq (Llama 3.3 70B Versatile)
   - **JustificaciÃ³n:** Llama 3.3 70B ofrece generaciÃ³n ultrarrÃ¡pida con alta calidad, ideal para respuestas contextuales complejas en tiempo real
   - Genera respuestas justificadas con citas

5. **ResponseVerifier (Agente Verificador)**
   - **LLM:** Groq (Llama 3.3 70B Versatile)
   - **JustificaciÃ³n:** Llama 3.3 70B sobresale en razonamiento complejo y validaciÃ³n lÃ³gica, necesario para detectar alucinaciones y verificar coherencia
   - Valida coherencia y evita alucinaciones

6. **Orchestrator (Agente Orquestador)**
   - **LLM:** Groq (Llama 3.1 8B Instant)
   - **JustificaciÃ³n:** Llama 3.1 8B garantiza decisiones de enrutamiento instantÃ¡neas, manteniendo el flujo del sistema fluido
   - Coordina el flujo entre todos los agentes

## ğŸ”„ Flujo del Sistema

```
Usuario â†’ Orchestrator â†’ QueryClassifier (Gemini)
                              â†“
                         [Clasifica intenciÃ³n]
                              â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                   â†“
              [general]           [bÃºsqueda/resumen/comparaciÃ³n]
                    â†“                   â†“
            Respuesta directa    SemanticRetriever (Groq)
            con Gemini                  â†“
                              RAGResponseGenerator (Groq)
                                        â†“
                              ResponseVerifier (Gemini)
                                        â†“
                                [Â¿VÃ¡lida?]
                              â†™          â†˜
                            SÃ­           No â†’ Regenerar
                            â†“
                    Respuesta Final + Trazabilidad
```

## ğŸ“¦ InstalaciÃ³n

### Requisitos Previos
- Python 3.10+
- ConexiÃ³n a Internet
- API Keys de Google (Gemini) y Groq

### OpciÃ³n 1: InstalaciÃ³n AutomÃ¡tica (Recomendada)

```bash
# 1. Navega al directorio del proyecto
cd ruta/a/tu/proyecto

# 2. Ejecuta el configurador
python setup_project.py
```

Este script:
- Crea la estructura de carpetas necesaria (`data/`, `faiss_index/`, `results/`)
- Opcionalmente copia tus documentos desde la ubicaciÃ³n antigua
- Crea el archivo `.gitignore`
- Verifica la estructura

### OpciÃ³n 2: InstalaciÃ³n Manual

```bash
# 1. Navega al directorio del proyecto
cd ruta/a/tu/proyecto

# 2. Crea la estructura de carpetas
mkdir data
mkdir faiss_index
mkdir results

# 3. Coloca tus documentos en la carpeta data/
# (arrastra o copia tus PDFs/TXT/HTML)
```

### Paso 2: Crear Entorno Virtual

```bash
python -m venv venv

# Activar en Windows
venv\Scripts\activate

# Activar en Linux/Mac
source venv/bin/activate
```

### Paso 3: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Paso 4: Configurar Variables de Entorno

Edita el archivo `.env`:

```env
# API Keys
GOOGLE_API_KEY=AIzaSyCkBEhiNP85HAvgDlTpPcUJl3UkCm3Aruc
GROQ_API_KEY=tu_api_key_aqui  # ObtÃ©n en https://console.groq.com/keys

# Rutas (rutas relativas - portables)
DOCUMENTS_PATH=./data
FAISS_INDEX_PATH=./faiss_index

# ConfiguraciÃ³n
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_RETRIEVAL_DOCS=5
```

### Paso 5: Verificar Documentos

AsegÃºrate de tener al menos 100 documentos en `./data/`

Para verificar:
```bash
# Windows
dir /s data\*.pdf data\*.txt data\*.html

# Linux/Mac
find data -type f \( -name "*.pdf" -o -name "*.txt" -o -name "*.html" \) | wc -l
```

## ğŸš€ Uso del Sistema

### Primera EjecuciÃ³n (IndexaciÃ³n)

```bash
python main.py
```

En la primera ejecuciÃ³n:
1. El sistema cargarÃ¡ todos los documentos de la carpeta `data`
2. GenerarÃ¡ embeddings y crearÃ¡ el Ã­ndice FAISS
3. GuardarÃ¡ el Ã­ndice en `faiss_index/` para ejecuciones futuras

**Nota:** La indexaciÃ³n puede tardar varios minutos dependiendo del nÃºmero de documentos.

### Ejecuciones Posteriores

```bash
python main.py
```

El sistema cargarÃ¡ el Ã­ndice existente y estarÃ¡ listo inmediatamente.

### Modo Interactivo

Una vez iniciado, puedes hacer consultas sobre agricultura:

```
ğŸ‘¤ Ingresa tu consulta: Â¿QuÃ© tÃ©cnicas de riego se mencionan en los documentos?
```

Tipos de consultas soportadas:
- **BÃºsqueda:** "Â¿QuÃ© informaciÃ³n hay sobre fertilizaciÃ³n orgÃ¡nica en los documentos?"
- **Resumen:** "Resume el contenido sobre control de plagas"
- **ComparaciÃ³n:** "Compara agricultura orgÃ¡nica con convencional segÃºn los documentos"
- **General:** "Â¿QuÃ© es la rotaciÃ³n de cultivos?" (respuestas sin necesidad de documentos)

## ğŸ§ª Casos de Prueba

Para ejecutar la suite de casos de prueba:

```bash
python test_cases.py
```

Esto ejecutarÃ¡ 12+ casos de prueba predefinidos y generarÃ¡:
- Reporte JSON con resultados detallados (`test_results.json`)
- Tabla resumen en consola
- EstadÃ­sticas de rendimiento

## ğŸ“Š Trazabilidad

El sistema mantiene trazabilidad completa de cada consulta:
- Timestamp de cada evento
- Agente que ejecutÃ³ la acciÃ³n
- Detalles de las decisiones
- Documentos utilizados
- Resultados de verificaciÃ³n

Para ver la trazabilidad, responde 'S' cuando se te pregunte despuÃ©s de cada consulta.

## ğŸ”‘ JustificaciÃ³n de SelecciÃ³n de LLMs

### Groq con Modelos Llama
**Usado en todos los agentes**

**Modelos utilizados:**
- **Llama 3.3 70B Versatile:** Para tareas de clasificaciÃ³n, generaciÃ³n y verificaciÃ³n
- **Llama 3.1 8B Instant:** Para tareas de orquestaciÃ³n y recuperaciÃ³n rÃ¡pida

**JustificaciÃ³n General:**
- **Velocidad extrema:** Groq ofrece la inferencia mÃ¡s rÃ¡pida del mercado (hasta 800 tokens/segundo)
- **Bajo costo:** API gratuita con lÃ­mites generosos para desarrollo y pruebas
- **Alta calidad:** Los modelos Llama 3.x son de cÃ³digo abierto y muy confiables
- **Disponibilidad:** No requiere lista de espera ni aprobaciones
- **Consistencia:** Usar una sola familia de modelos simplifica la arquitectura

**Estrategia de SelecciÃ³n por Agente:**

1. **QueryClassifier (Llama 3.3 70B):**
   - Requiere comprensiÃ³n profunda del lenguaje natural
   - El modelo 70B ofrece mejor precisiÃ³n en clasificaciÃ³n de intenciones
   - Velocidad suficiente para no afectar experiencia de usuario

2. **SemanticRetriever (Llama 3.1 8B Instant):**
   - OperaciÃ³n de alta frecuencia que requiere mÃ¡xima velocidad
   - 8B Instant es el mÃ¡s rÃ¡pido disponible
   - La recuperaciÃ³n es principalmente basada en embeddings, el LLM es auxiliar

3. **RAGResponseGenerator (Llama 3.3 70B):**
   - GeneraciÃ³n de texto requiere el modelo mÃ¡s capaz
   - 70B ofrece respuestas mÃ¡s coherentes y contextuales
   - Balance Ã³ptimo entre calidad y velocidad

4. **ResponseVerifier (Llama 3.3 70B):**
   - Razonamiento crÃ­tico requiere modelo mÃ¡s grande
   - DetecciÃ³n de alucinaciones necesita capacidad analÃ­tica profunda
   - 70B ofrece mejor validaciÃ³n lÃ³gica

5. **Orchestrator (Llama 3.1 8B Instant):**
   - Decisiones de enrutamiento son simples y binarias
   - Velocidad es crÃ­tica para mantener flujo fluido
   - 8B Instant es perfecto para esta tarea

### Alternativa Considerada: Gemini

**Por quÃ© NO se usÃ³ Gemini:**
- Requiere configuraciÃ³n adicional de Google Cloud
- LÃ­mites de API mÃ¡s restrictivos en plan gratuito
- Mayor latencia comparado con Groq
- Complejidad adicional al manejar dos proveedores diferentes

**CuÃ¡ndo considerar Gemini:**
- Proyectos con presupuesto para APIs premium
- Casos que requieren capacidades multimodales (imÃ¡genes, video)
- Cuando se necesita integraciÃ³n con ecosistema Google

### Embeddings: Sentence Transformers Local

**Modelo:** all-MiniLM-L6-v2

**JustificaciÃ³n:**
- **Gratuito y sin lÃ­mites:** No consume cuota de API
- **RÃ¡pido:** Procesamiento local en GPU/CPU
- **Eficiente:** Solo 80MB de memoria
- **Portable:** Funciona sin conexiÃ³n a internet (despuÃ©s de primera descarga)
- **Calidad:** Excelente para embeddings en espaÃ±ol e inglÃ©s

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ main.py                 # Sistema principal multi-agente
â”œâ”€â”€ test_cases.py          # Suite de casos de prueba
â”œâ”€â”€ requirements.txt       # Dependencias
â”œâ”€â”€ .env                   # Variables de entorno
â”œâ”€â”€ README.md             # Este archivo
â”œâ”€â”€ data/                 # Documentos (100+)
â”‚   â”œâ”€â”€ *.pdf
â”‚   â”œâ”€â”€ *.txt
â”‚   â””â”€â”€ *.html
â”œâ”€â”€ faiss_index/          # Ãndice FAISS (generado)
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â””â”€â”€ test_results.json     # Resultados de pruebas (generado)
```

## ğŸ› ï¸ Herramientas (Tools) Implementadas

Las herramientas estÃ¡n integradas dentro de los agentes:

1. **Document Loaders** (PyPDFLoader, TextLoader, UnstructuredHTMLLoader)
2. **Text Splitter** (RecursiveCharacterTextSplitter)
3. **Embeddings Generator** (GoogleGenerativeAIEmbeddings)
4. **Vector Store** (FAISS)
5. **LLM Chains** (ChatPromptTemplate + LLM + OutputParser)
6. **Similarity Search** (FAISS similarity_search)
7. **Traceability Logger** (Sistema de logging personalizado)

## ğŸ“ GeneraciÃ³n de Informe TÃ©cnico

Para documentar los casos de uso:

1. Ejecuta `test_cases.py`
2. Revisa `test_results.json`
3. Captura pantallas del sistema en ejecuciÃ³n
4. Documenta:
   - DescripciÃ³n del dominio seleccionado
   - JustificaciÃ³n de LLMs por agente
   - Resultados de los 10+ casos de uso
   - Trazabilidad de ejecuciones
   - AnÃ¡lisis de rendimiento

## ğŸ¥ Video de SustentaciÃ³n

Contenido sugerido para el pitch (mÃ¡x. 5 minutos):

1. **IntroducciÃ³n (30s)**
   - PresentaciÃ³n del equipo
   - Dominio seleccionado

2. **Arquitectura (1m)**
   - Diagrama de agentes
   - Flujo del sistema
   - JustificaciÃ³n de LLMs

3. **DemostraciÃ³n (2m 30s)**
   - Caso de bÃºsqueda
   - Caso de resumen
   - Caso de comparaciÃ³n
   - Caso general
   - VisualizaciÃ³n de trazabilidad

4. **Aspectos TÃ©cnicos (1m)**
   - IntegraciÃ³n LangChain
   - RAG con FAISS
   - Manejo de errores y verificaciÃ³n

5. **Conclusiones (30s)**
   - Logros alcanzados
   - Posibles mejoras

## ğŸ› SoluciÃ³n de Problemas

### Error: "GROQ_API_KEY no configurada"
- ObtÃ©n tu API key en https://console.groq.com/keys
- AÃ±Ã¡dela al archivo `.env`

### Error al cargar documentos
- Verifica que la ruta sea correcta
- Asegura que los archivos tengan permisos de lectura
- Verifica que los PDFs no estÃ©n encriptados

### Error de memoria al indexar
- Reduce `chunk_size` en el cÃ³digo
- Procesa documentos en lotes mÃ¡s pequeÃ±os
- Aumenta la memoria disponible para Python

### Respuestas lentas
- Verifica tu conexiÃ³n a Internet
- Los LLMs requieren conexiÃ³n para inferencia
- Primera ejecuciÃ³n siempre es mÃ¡s lenta (embeddings)

## ğŸ“š Referencias

- [LangChain Documentation](https://python.langchain.com/)
- [Google Gemini API](https://ai.google.dev/)
- [Groq API](https://console.groq.com/docs)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)

## ğŸ‘¥ Equipo

[AÃ±ade aquÃ­ los nombres de los integrantes del grupo]

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico para la Universidad Nacional de Colombia.

---

**Fecha de Entrega:** MiÃ©rcoles 10 de diciembre de 2025, 12:00 meridiano  
**Profesor:** Jaime Alberto GuzmÃ¡n Luna